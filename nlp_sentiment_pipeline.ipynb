{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f3a9e-56d4-409f-ae0d-f6cb2c108fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01_preprocessing.ipynb\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------ Path configuration ------------------------ #\n",
    "# Base folder for this project\n",
    "BASE_DIR = Path(r\"C:\\Users\\Admin\\Desktop\\Tai-Seale Lab\")\n",
    "\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "\n",
    "# If you later create \"raw\" and \"processed\" subfolders, you can change RAW_DIR.\n",
    "# For now we assume the original CSV is directly under DATA_DIR.\n",
    "RAW_DIR = DATA_DIR\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_CSV = RAW_DIR / \"message_text 2025 06 05_sentiment_analysis_scrambled_with_count(in).csv\"\n",
    "\n",
    "print(\"Reading raw CSV from:\", RAW_CSV)\n",
    "\n",
    "# ------------------------ Load raw data ------------------------ #\n",
    "# Use latin1 because UTF-8 raised a UnicodeDecodeError.\n",
    "df = pd.read_csv(RAW_CSV, encoding=\"latin1\")\n",
    "\n",
    "# AE = message from patient\n",
    "COL_AE = \"Deidentified text Message text from patient (Extracted) \"\n",
    "# AF = message to patient (provider response)\n",
    "COL_AF = \"Deidentified text Message text to patient (Extracted)\"\n",
    "\n",
    "# Safety check: make sure the columns exist\n",
    "assert COL_AE in df.columns, f\"Column not found: {COL_AE}\"\n",
    "assert COL_AF in df.columns, f\"Column not found: {COL_AF}\"\n",
    "\n",
    "# ------------------------ Remove old helper columns if re-running ------------------------ #\n",
    "# This prevents duplicated columns like AE_raw.1, AE_clean.2, etc.\n",
    "for col in [\"AE_raw\", \"AF_raw\", \"AE_clean\", \"AF_clean\"]:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# ------------------------ Preserve raw text ------------------------ #\n",
    "# Keep the exact original text in separate columns for reference.\n",
    "df[\"AE_raw\"] = df[COL_AE]\n",
    "df[\"AF_raw\"] = df[COL_AF]\n",
    "\n",
    "\n",
    "# ------------------------ Clean <Redacted> ------------------------ #\n",
    "def clean_redacted(text):\n",
    "    \"\"\"\n",
    "    Clean a single text cell:\n",
    "    - Keep NaN as NaN (do not force to empty string).\n",
    "    - Replace any <Redacted ...> placeholder with a neutral token [NAME].\n",
    "    - Normalize whitespace.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        # Return NaN for non-string values (e.g., missing values)\n",
    "        return np.nan\n",
    "\n",
    "    # Replace any variant like \"<Redacted>\", \"< redacted >\", \"<Redacted name>\" with [NAME]\n",
    "    cleaned = re.sub(r\"<\\s*redacted[^>]*>\", \"[NAME]\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Collapse multiple whitespaces into a single space\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# Apply cleaning to AE / AF to create \"clean\" versions\n",
    "df[\"AE_clean\"] = df[\"AE_raw\"].apply(clean_redacted)\n",
    "df[\"AF_clean\"] = df[\"AF_raw\"].apply(clean_redacted)\n",
    "\n",
    "def fix_mojibake_quotes(text):\n",
    "    \"\"\"\n",
    "    Fix mojibake patterns where apostrophes or quotes were corrupted.\n",
    "    Examples:\n",
    "      \"I?聙?m\"      -> \"I'm\"\n",
    "      \"She?聙?s\"    -> \"She's\"\n",
    "      \"?聙?wanna?聙聺\" -> \"'wanna'\"\n",
    "    Strategy:\n",
    "      1) Replace any pattern starting with '?' followed by 1–5 non-alphanumeric\n",
    "         garbage characters as a simple apostrophe.\n",
    "      2) Remove remaining non-ASCII junk characters.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # Step 1: collapse patterns like \"?聙?\", \"?聙聺\", \"?聙隆卤\" into a single apostrophe\n",
    "    # Pattern: '?' + 1–5 non-alphanumeric, non-space characters\n",
    "    text = re.sub(r\"\\?[^A-Za-z0-9\\s]{1,5}\", \"'\", text)\n",
    "\n",
    "    # Step 2 (optional but helpful here): remove remaining non-ASCII junk\n",
    "    # This will strip stray characters like 聺, 隆, 卤 that slipped through.\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "\n",
    "    # Normalize repeated apostrophes and whitespace\n",
    "    text = text.replace(\"''\", \"'\")\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df[\"AE_clean\"] = df[\"AE_clean\"].apply(fix_mojibake_quotes)\n",
    "df[\"AF_clean\"] = df[\"AF_clean\"].apply(fix_mojibake_quotes)\n",
    "# ------------------------ Save processed data ------------------------ #\n",
    "CLEAN_CSV = PROCESSED_DIR / \"message_text_cleaned.csv\"\n",
    "df.to_csv(CLEAN_CSV, index=False)\n",
    "\n",
    "print(\"Preprocessing finished.\")\n",
    "print(\"Cleaned file saved to:\", CLEAN_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d198d-3ba5-4e03-b386-a492ba6556f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af18b4-df73-43d7-afde-706ae16be844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_vader.ipynb\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ------------------------ Path configuration ------------------------ #\n",
    "BASE_DIR = Path(r\"C:\\Users\\Admin\\Desktop\\Tai-Seale Lab\")\n",
    "\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CLEAN_CSV = PROCESSED_DIR / \"message_text_cleaned.csv\"\n",
    "\n",
    "print(\"Loading cleaned data from:\", CLEAN_CSV)\n",
    "\n",
    "# ------------------------ Load cleaned data ------------------------ #\n",
    "# Use latin1 for consistency with preprocessing step\n",
    "df = pd.read_csv(CLEAN_CSV, encoding=\"latin1\")\n",
    "\n",
    "# Expected columns from preprocessing\n",
    "AE_RAW_COL = \"AE_raw\"\n",
    "AF_RAW_COL = \"AF_raw\"\n",
    "AE_CLEAN_COL = \"AE_clean\"\n",
    "AF_CLEAN_COL = \"AF_clean\"\n",
    "\n",
    "for col in [AE_RAW_COL, AF_RAW_COL, AE_CLEAN_COL, AF_CLEAN_COL]:\n",
    "    assert col in df.columns, f\"Column not found: {col}\"\n",
    "\n",
    "print(\"Columns available:\", df.columns.tolist())\n",
    "\n",
    "# ------------------------ Create master sentiment file if not exists ------------------------ #\n",
    "MASTER_PATH = RESULTS_DIR / \"sentiments_master.csv\"\n",
    "\n",
    "if not MASTER_PATH.exists():\n",
    "    base_df = df[[AE_CLEAN_COL, AF_CLEAN_COL]].copy()\n",
    "    base_df.to_csv(MASTER_PATH, index=True)\n",
    "    print(\"Created new master file:\", MASTER_PATH)\n",
    "else:\n",
    "    print(\"Master file already exists:\", MASTER_PATH)\n",
    "\n",
    "# ------------------------ VADER setup ------------------------ #\n",
    "nltk.download(\"vader_lexicon\", quiet=True)\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_score(text):\n",
    "    \"\"\"\n",
    "    Compute VADER compound score for a given text.\n",
    "    - If text is empty or NaN, return 0.0 as a neutral / no-information score.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return 0.0\n",
    "    scores = sia.polarity_scores(text)\n",
    "    return float(scores[\"compound\"])\n",
    "\n",
    "# ------------------------ Apply VADER to AE / AF ------------------------ #\n",
    "df[\"AE_vader\"] = df[AE_CLEAN_COL].apply(vader_score)\n",
    "df[\"AF_vader\"] = df[AF_CLEAN_COL].apply(vader_score)\n",
    "\n",
    "print(\"Sample VADER scores:\")\n",
    "print(\n",
    "    df[[AE_CLEAN_COL, \"AE_vader\", AF_CLEAN_COL, \"AF_vader\"]]\n",
    "    .head(5)\n",
    "    .to_string(index=False)\n",
    ")\n",
    "\n",
    "# ------------------------ Export aligned results ------------------------ #\n",
    "vader_dir = RESULTS_DIR / \"vader\"\n",
    "vader_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Use RowID if it exists, otherwise fallback to index\n",
    "if \"RowID\" in df.columns:\n",
    "    row_id = df[\"RowID\"]\n",
    "else:\n",
    "    row_id = df.index\n",
    "\n",
    "# AE-only table\n",
    "ae_out = pd.DataFrame({\n",
    "    \"RowID\": row_id,\n",
    "    \"AE_raw\": df[AE_RAW_COL],\n",
    "    \"AE_clean\": df[AE_CLEAN_COL],\n",
    "    \"AE_vader\": df[\"AE_vader\"],\n",
    "})\n",
    "\n",
    "# AF-only table\n",
    "af_out = pd.DataFrame({\n",
    "    \"RowID\": row_id,\n",
    "    \"AF_raw\": df[AF_RAW_COL],\n",
    "    \"AF_clean\": df[AF_CLEAN_COL],\n",
    "    \"AF_vader\": df[\"AF_vader\"],\n",
    "})\n",
    "\n",
    "# Combined AE + AF table (most convenient)\n",
    "both_out = pd.DataFrame({\n",
    "    \"RowID\": row_id,\n",
    "    \"AE_raw\": df[AE_RAW_COL],\n",
    "    \"AE_clean\": df[AE_CLEAN_COL],\n",
    "    \"AE_vader\": df[\"AE_vader\"],\n",
    "    \"AF_raw\": df[AF_RAW_COL],\n",
    "    \"AF_clean\": df[AF_CLEAN_COL],\n",
    "    \"AF_vader\": df[\"AF_vader\"],\n",
    "})\n",
    "\n",
    "ae_path = vader_dir / \"AE_vader_results_aligned.csv\"\n",
    "af_path = vader_dir / \"AF_vader_results_aligned.csv\"\n",
    "both_path = vader_dir / \"vader_results_aligned.csv\"\n",
    "\n",
    "ae_out.to_csv(ae_path, index=False)\n",
    "af_out.to_csv(af_path, index=False)\n",
    "both_out.to_csv(both_path, index=False)\n",
    "\n",
    "print(\"VADER results saved to:\")\n",
    "print(\"  \", ae_path)\n",
    "print(\"  \", af_path)\n",
    "print(\"  \", both_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c5d5e-032a-4322-be02-83e2db8a33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Summary statistics (print only) ------------------------ #\n",
    "# Ensure numeric types\n",
    "df[\"AE_vader\"] = pd.to_numeric(df[\"AE_vader\"], errors=\"coerce\")\n",
    "df[\"AF_vader\"] = pd.to_numeric(df[\"AF_vader\"], errors=\"coerce\")\n",
    "\n",
    "# Compute delta (provider - patient)\n",
    "df[\"delta_vader\"] = df[\"AF_vader\"] - df[\"AE_vader\"]\n",
    "\n",
    "# Main summary dictionary\n",
    "summary = {\n",
    "    \"Patient_mean\": df[\"AE_vader\"].mean(),\n",
    "    \"Patient_std\": df[\"AE_vader\"].std(),\n",
    "    \"Patient_median\": df[\"AE_vader\"].median(),\n",
    "    \"Patient_min\": df[\"AE_vader\"].min(),\n",
    "    \"Patient_max\": df[\"AE_vader\"].max(),\n",
    "\n",
    "    \"Provider_mean\": df[\"AF_vader\"].mean(),\n",
    "    \"Provider_std\": df[\"AF_vader\"].std(),\n",
    "    \"Provider_median\": df[\"AF_vader\"].median(),\n",
    "    \"Provider_min\": df[\"AF_vader\"].min(),\n",
    "    \"Provider_max\": df[\"AF_vader\"].max(),\n",
    "\n",
    "    \"Delta_mean\": df[\"delta_vader\"].mean(),\n",
    "    \"Delta_std\": df[\"delta_vader\"].std(),\n",
    "    \"Delta_median\": df[\"delta_vader\"].median(),\n",
    "}\n",
    "\n",
    "# Optional positivity ratios\n",
    "summary[\"Patient_positive_rate\"] = (df[\"AE_vader\"] > 0.05).mean()\n",
    "summary[\"Patient_negative_rate\"] = (df[\"AE_vader\"] < -0.05).mean()\n",
    "summary[\"Patient_neutral_rate\"]  = ((df[\"AE_vader\"] >= -0.05) & (df[\"AE_vader\"] <= 0.05)).mean()\n",
    "\n",
    "summary[\"Provider_positive_rate\"] = (df[\"AF_vader\"] > 0.05).mean()\n",
    "summary[\"Provider_negative_rate\"] = (df[\"AF_vader\"] < -0.05).mean()\n",
    "summary[\"Provider_neutral_rate\"]  = ((df[\"AF_vader\"] >= -0.05) & (df[\"AF_vader\"] <= 0.05)).mean()\n",
    "\n",
    "# Convert to DataFrame for clean printing\n",
    "summary_df = pd.DataFrame(summary.items(), columns=[\"Metric\", \"Value\"])\n",
    "\n",
    "print(\"\\n===== VADER Summary Statistics =====\")\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"====================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4520891e-f714-4ff9-9621-11164908bb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned data from: C:\\Users\\Admin\\Desktop\\Tai-Seale Lab\\data\\processed\\message_text_cleaned.csv\n",
      "Columns available: ['RowID', 'Unnamed: 0.1', 'Unnamed: 0', 'Provider ID', 'Staff message ID from patient', 'Scrambled Identifier', 'Time message sent by patient', 'Day_of_the_week from patient', 'PAT_ID', 'Patient age at time of msg from patient', 'Patient race', 'Patient sex', 'Message text from patient', 'Message text from patient (Extracted)', 'Message text from patient (Extracted) (# Words)', 'Message text from patient (Extracted) (# Char)', 'Message ID to patient', 'Message to patient sent by', 'PROVIDER_TYPE', 'PRIMARY_SPECIALTY', 'WAS_ART_USED_YN', 'BEFORE_AFTER_FIRST_ART_USE', 'Message text to patient', 'Message text to patient (Extracted)', 'Message text to patient (Extracted) (# Words)', 'Message text to patient (Extracted) (# Char)', 'sentiment of message from Patient (Extracted)', 'sentiment of message to Patient (Extracted)', 'Message text from patient (Extracted) person names', 'Message text to patient (Extracted) person names', 'Deidentified text Message text from patient (Extracted) ', 'Deidentified text Message text to patient (Extracted)', 'Unnamed: 32', 'Unnamed: 33', 'Unnamed: 34', 'Unnamed: 35', 'Unnamed: 36', 'Unnamed: 37', 'Unnamed: 38', 'Unnamed: 39', 'Unnamed: 40', 'Unnamed: 41', 'Unnamed: 42', 'Unnamed: 43', 'Unnamed: 44', 'Unnamed: 45', 'Unnamed: 46', 'Unnamed: 47', 'Unnamed: 48', 'Unnamed: 49', 'Unnamed: 50', 'Unnamed: 51', 'Unnamed: 52', 'Unnamed: 53', 'Unnamed: 54', 'Unnamed: 55', 'Unnamed: 56', 'Unnamed: 57', 'AE_raw', 'AF_raw', 'AE_clean', 'AF_clean']\n",
      "Loading model: cardiffnlp/twitter-roberta-base-sentiment-latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing RoBERTa sentiment for AE_clean...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing RoBERTa sentiment for AE_clean...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    108\u001b[0m ae_texts \u001b[38;5;241m=\u001b[39m df[AE_CLEAN_COL]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m--> 109\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAE_roberta\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mroberta_sentiment_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mae_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing RoBERTa sentiment for AF_clean...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m af_texts \u001b[38;5;241m=\u001b[39m df[AF_CLEAN_COL]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "Cell \u001b[1;32mIn[3], line 85\u001b[0m, in \u001b[0;36mroberta_sentiment_score\u001b[1;34m(texts, batch_size, max_length)\u001b[0m\n\u001b[0;32m     75\u001b[0m enc \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[0;32m     76\u001b[0m     processed_batch,\n\u001b[0;32m     77\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     83\u001b[0m enc \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m enc\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m---> 85\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menc)\n\u001b[0;32m     86\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits  \u001b[38;5;66;03m# [batch_size, num_labels]\u001b[39;00m\n\u001b[0;32m     87\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# convert to probabilities\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1188\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;124;03mtoken_type_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;124;03m    Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,1]`:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1188\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1199\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1200\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:862\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    860\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 862\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    876\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:606\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    602\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m    604\u001b[0m layer_head_mask \u001b[38;5;241m=\u001b[39m head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:543\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[0;32m    540\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    541\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[1;32m--> 543\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\transformers\\pytorch_utils.py:257\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:552\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    551\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 552\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:479\u001b[0m, in \u001b[0;36mRobertaOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 479\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    481\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Sentiment\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    Runs the forward pass.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 03_roberta.ipynb\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# ------------------------ Path configuration ------------------------ #\n",
    "BASE_DIR = Path(r\"C:\\Users\\Admin\\Desktop\\Tai-Seale Lab\")\n",
    "\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CLEAN_CSV = PROCESSED_DIR / \"message_text_cleaned.csv\"\n",
    "\n",
    "print(\"Loading cleaned data from:\", CLEAN_CSV)\n",
    "\n",
    "# ------------------------ Load cleaned data ------------------------ #\n",
    "# Use latin1 to be consistent with preprocessing\n",
    "df = pd.read_csv(CLEAN_CSV, encoding=\"latin1\")\n",
    "\n",
    "AE_RAW_COL = \"AE_raw\"\n",
    "AF_RAW_COL = \"AF_raw\"\n",
    "AE_CLEAN_COL = \"AE_clean\"\n",
    "AF_CLEAN_COL = \"AF_clean\"\n",
    "\n",
    "for col in [AE_RAW_COL, AF_RAW_COL, AE_CLEAN_COL, AF_CLEAN_COL]:\n",
    "    assert col in df.columns, f\"Column not found: {col}\"\n",
    "\n",
    "print(\"Columns available:\", df.columns.tolist())\n",
    "\n",
    "# ------------------------ RoBERTa sentiment model setup ------------------------ #\n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "print(\"Loading model:\", MODEL_NAME)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "id2label = model.config.id2label  # e.g. {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "\n",
    "def roberta_sentiment_score(texts, batch_size=32, max_length=128):\n",
    "    \"\"\"\n",
    "    Compute sentiment scores for a list of texts using RoBERTa.\n",
    "\n",
    "    For each text, we:\n",
    "      1) Run the model to obtain logits for [negative, neutral, positive].\n",
    "      2) Apply softmax to convert logits into probabilities.\n",
    "      3) Define a continuous sentiment score:\n",
    "            score = P(positive) - P(negative)\n",
    "         which lies in the range [-1, 1].\n",
    "\n",
    "    Empty or NaN texts will receive a score of 0.0 (neutral / no information).\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    n = len(texts)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, n, batch_size):\n",
    "            batch_texts = texts[start:start + batch_size]\n",
    "\n",
    "            # Replace non-string / empty values with empty string\n",
    "            processed_batch = [\n",
    "                t if isinstance(t, str) and t.strip() != \"\" else \"\"\n",
    "                for t in batch_texts\n",
    "            ]\n",
    "\n",
    "            enc = tokenizer(\n",
    "                processed_batch,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "            outputs = model(**enc)\n",
    "            logits = outputs.logits  # [batch_size, num_labels]\n",
    "            probs = torch.softmax(logits, dim=-1).cpu().numpy()  # convert to probabilities\n",
    "\n",
    "            for p in probs:\n",
    "                # Map indices to labels using id2label to be robust to label ordering\n",
    "                if id2label:\n",
    "                    label_prob = {id2label[i].lower(): float(p[i]) for i in range(len(p))}\n",
    "                    p_neg = label_prob.get(\"negative\", 0.0)\n",
    "                    p_pos = label_prob.get(\"positive\", 0.0)\n",
    "                else:\n",
    "                    # Fallback: assume [neg, neu, pos]\n",
    "                    p_neg = float(p[0])\n",
    "                    p_pos = float(p[2])\n",
    "\n",
    "                score = p_pos - p_neg  # continuous sentiment polarity in [-1, 1]\n",
    "                scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ------------------------ Apply RoBERTa to AE / AF ------------------------ #\n",
    "print(\"Computing RoBERTa sentiment for AE_clean...\")\n",
    "ae_texts = df[AE_CLEAN_COL].tolist()\n",
    "df[\"AE_roberta\"] = roberta_sentiment_score(ae_texts, batch_size=32, max_length=128)\n",
    "\n",
    "print(\"Computing RoBERTa sentiment for AF_clean...\")\n",
    "af_texts = df[AF_CLEAN_COL].tolist()\n",
    "df[\"AF_roberta\"] = roberta_sentiment_score(af_texts, batch_size=32, max_length=128)\n",
    "\n",
    "print(\"Sample RoBERTa scores:\")\n",
    "print(\n",
    "    df[[AE_CLEAN_COL, \"AE_roberta\", AF_CLEAN_COL, \"AF_roberta\"]]\n",
    "    .head(5)\n",
    "    .to_string(index=False)\n",
    ")\n",
    "\n",
    "# ------------------------ Export aligned results ------------------------ #\n",
    "roberta_dir = RESULTS_DIR / \"roberta\"\n",
    "roberta_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Use RowID if it exists, otherwise use index\n",
    "if \"RowID\" in df.columns:\n",
    "    row_id = df[\"RowID\"]\n",
    "else:\n",
    "    row_id = df.index\n",
    "\n",
    "# AE-only table\n",
    "ae_out = pd.DataFrame({\n",
    "    \"RowID\": row_id,\n",
    "    \"AE_raw\": df[AE_RAW_COL],\n",
    "    \"AE_clean\": df[AE_CLEAN_COL],\n",
    "    \"AE_roberta\": df[\"AE_roberta\"],\n",
    "})\n",
    "\n",
    "# AF-only table\n",
    "af_out = pd.DataFrame({\n",
    "    \"RowID\": row_id,\n",
    "    \"AF_raw\": df[AF_RAW_COL],\n",
    "    \"AF_clean\": df[AF_CLEAN_COL],\n",
    "    \"AF_roberta\": df[\"AF_roberta\"],\n",
    "})\n",
    "\n",
    "# Combined AE + AF table (similar style to VADER)\n",
    "both_out = pd.DataFrame({\n",
    "    \"RowID\": row_id,\n",
    "    \"AE_raw\": df[AE_RAW_COL],\n",
    "    \"AE_clean\": df[AE_CLEAN_COL],\n",
    "    \"AE_roberta\": df[\"AE_roberta\"],\n",
    "    \"AF_raw\": df[AF_RAW_COL],\n",
    "    \"AF_clean\": df[AF_CLEAN_COL],\n",
    "    \"AF_roberta\": df[\"AF_roberta\"],\n",
    "})\n",
    "\n",
    "ae_path = roberta_dir / \"AE_roberta_results_aligned.csv\"\n",
    "af_path = roberta_dir / \"AF_roberta_results_aligned.csv\"\n",
    "both_path = roberta_dir / \"roberta_results_aligned.csv\"\n",
    "\n",
    "ae_out.to_csv(ae_path, index=False)\n",
    "af_out.to_csv(af_path, index=False)\n",
    "both_out.to_csv(both_path, index=False)\n",
    "\n",
    "print(\"RoBERTa results saved to:\")\n",
    "print(\"  \", ae_path)\n",
    "print(\"  \", af_path)\n",
    "print(\"  \", both_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3d09551-a858-45d0-9afd-105e801e2ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowID', 'AE_raw', 'AE_clean', 'AE_roberta', 'AF_raw', 'AF_clean',\n",
       "       'AF_roberta', 'WAS_ART_USED_YN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\Tai-Seale Lab\\results\\roberta\\roberta_results_aligned.csv\")\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ba18bd-b48e-4b44-854d-b3c49fb03953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHWCAYAAAA/0l4bAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUnRJREFUeJzt3Qd4FNX6+PE3oSS0FHrvSJOiqAg2RKTo9YrgveC1oGKniFhREcGCFbCAXJGif0WwgWJBKSIWVIooICBVpKOmhxSS+T/v4W5+u8kmW7LJbPl+nmdYMnt25uzZ2dl3zznzbpRlWZYAAACgXEWX7+4AAACgCMIAAABsQBAGAABgA4IwAAAAGxCEAQAA2IAgDAAAwAYEYQAAADYgCAMAALABQRgAAIANCMIQEaKiouTRRx/1WE7LaNlI1qtXL7OEo2eeeUbatWsn+fn5dlcl6C1dulSqV68ux44ds7sqQNgiCEPAzZs3zwQyjiU2NlZOOeUUGTlypBw5coQWd/LNN9/IgAEDpFGjRqadmjZtKpdddpnMnz+/TNvp119/NQHn3r17Q/L1OHjwoKn/xo0bvX5MamqqPP3003L//fdLdPT/nfqcj1Vd4uLi5IILLpBPPvnE7/oV3ma1atWkQ4cO8vjjj0tmZqZL2euvv75Ieef3jsOqVatc7qtQoYLUrVtXrrzyStm6davLlwhPizdBdv/+/aV169YyefJkCZSzzjrL7P+VV14p8dyxbt06sZOjHtr+Bw4cKHK/tt+pp54qdguV9kTxKpZwH1AqkyZNkhYtWkhWVpYJNvRE8emnn8rmzZulatWq5dq6x48fl4oVg+twf/fdd2XIkCHStWtXufPOOyUxMVH27Nkjq1evllmzZsl//vOfMg3CJk6caD5Mmjdv7nLfF198IaEQhGn9te7aft6YM2eOnDhxQq666qoi91188cVy3XXXif6U7u+//26OVQ2GP/vsM+nXr59fdXRsU6Wnp8vXX38t48ePl59//tm89s5iYmLktddeK7INDbQKGz16tJx55pmSm5srv/zyi8ycOdMEaPq+GjRokAmcHHS/t99+u1xxxRXmPod69ep59RxuvfVWueeee0xb16hRQ0pjx44dsnbtWvOavfXWW6ZewS47O1ueeuopeemllyTYhGJ7wg39AW8gkObOnas/Cm+tXbvWZf3YsWPN+vnz5xf72PT0dFtfjAkTJpg6BkpGRkax93Xo0MHq2LGjlZ2dXeS+I0eOWGXp3XffNc/zyy+/tEKRHltafz3WvNW5c2frmmuuKbJetzNixAiXdb/++qtZP2DAAL/q526b6sorr7Sio6Ot48ePF6wbNmyYVa1aNY/b1NdKt6uvnbNXXnnFrH/66aeLPObYsWPmPj2u/aHHYYUKFazZs2dbpfXII49YdevWtd5//30rKirK2rNnj9fnjvLmqEfXrl2tmJgY68CBAy73X3DBBea9a6dQak8Uj+FIlJvevXubW+3tcQzD6JyTXbt2ySWXXGK+aV999dXmvoyMDLn77rulSZMmppegbdu28txzz5meCgcdDrjwwguL7Efn++jwng7TlDQnTHvntEdBhxxatWol//3vf4ut+5tvvindunWTKlWqSM2aNWXo0KHyxx9/uB2iWL9+vZx//vmmt+/BBx8sdpv6vHX/lStXLnKfDjMVfk7Tpk2Tjh07mvpqT4b2UiQlJbmU02/F//jHP8xz06EKLduyZUt54403XIYo/vWvf5n/a/s5hqi0N8XxPJyHqxzDYO+8847pEdG21ddK2zclJcX0FowZM8bUWV/PG264wawrTRtqT53WTdtQ96dzuZzro+2mdF+O+uvzKo4ec9pr1KdPH/FG+/btpXbt2uY1cnb06FEZPny4aX9t2y5dusjrr78u3qpfv76payB7Zc877zxzW7iuxdGevjvuuMO8p/S1qFWrljke3A1N62vauXNn+fDDD13W6+u+bds2c+stHWLXY0aPz/j4eL+H3HVoTdvQXbt//vnn5r6PP/7Y/J2WlmaOTX1f6HlEn4/2UG7YsMGrfen7Ny8vz/SGeaK9rI899pg5l+i+dJ/6+MLvBW/eo+XZnrAXQRjKjeNDQk/6zicuHe7Rk6MGWYMHDzaB1j//+U+ZOnWqmZcyZcoU84Fx7733ytixYwseq0N5OnR3+PBhl/3oyU2Hq/RDvjibNm2Svn37mg9VDc70w3zChAmyaNGiImWfeOIJM6zUpk0bUxc9qa9YscIEWsnJyS5l//rrLzPHS4fINGhyFyQ6NGvWzGxn//79HttOAy59/uecc4688MILpr46BKFtp8NSznbu3GlOzvph8/zzz5thTg14t2zZYu7XeuuQltIPif/3//6fWTTwKInODdIPuQceeEBuvPFG+eCDD+S2224z///tt99MO+qQlwZDOvfK3zbUwFJfdw1wtP46kV7ncenQoNJ66lC3uuWWWwrqr9sqznfffWduTz/9dPGGBhdaD2075yFtDRJ1X/pl4dlnnzUfftq2+poUpsPwf/75p1k08NEPSQ0cdJjZXRDmKOu86Dw2TxzBk3NdS6JDWNoe+v548cUXzWuor4U+t8Lz1ZQGzo72c9D3ib4O7t4v7vzwww/muNShYP3SoceJHr/+OOOMM0zQol8KClu4cKFpB8cQsj43HVrW88qMGTPM0KoGno45dJ7odAo9bnV6gJ5TSnLTTTfJI488Yo4xPXfpvEJ9z7g7D3l6j5Zne8JmJfSSAX5xdIEvX77cDIf88ccf1oIFC6xatWpZVapUsfbv318wDKPlHnjgAZfHL1682Kx//PHHiwzlaLf7zp07zd/bt2835V566SWXcnfccYdVvXp1KzMzs2Bd4SGZgQMHWrGxsdbvv//uMgSlQy/Ob4u9e/eadU888YTLPjZt2mRVrFjRZb0OUehjZ86c6VU76RCPlq9cubJ14YUXWuPHj7e+/vprKy8vz6WcrtNyb731lsv6pUuXFlnfrFkzs2716tUF644ePWqGVO6++26vhiP1eehSeBjs1FNPtXJycgrWX3XVVeb1KDxk16NHD1OP0rThG2+8UbBOh2vr169vDR482O/hyIcfftiUT0tLK3Kfrh8+fLg5VrWt1q1bZ/Xv39+sf/bZZwvKTZs2zax78803C9Zpe+jz1eMtNTXVZZvuFj3usrKyXPbveB+4W/r161fkdZgzZ46p68GDB80x0Lp1a/M6/Pjjj14NRzq/LxzWrFlTpN0dnnzySXOf8xC54z3ubfuPHDnSatKkiZWfn2/+/uKLL8zjf/rpJ7+Gz8aNG2dVqlTJ+vvvv12Ok4SEBOvGG28sWBcfH+92WNgT53rs2rXLHKejR48udjhy48aNpvxNN93ksp177rnHrF+5cqXP79HybE/Yh54wlBkd+qlTp44ZUtRvgzpUpd+cdXjJWeEJpTp5XyckO3prHHR4Uj/fHD0iesWl9jjpt18HHTp47733zKRq/cbrjpbRHp2BAweaqxEd9Jt94UnY2tujQ4H//ve/XXoodFhJe3W+/PJLl/I6DKG9VN7QHiRNA6A9ENp7p0MZOrSk23XuedBJ3Nrjot+aneugPRTapoXroFfhOYaolL4G2pO4e/duKQ3tEahUqVLB3927dzevhz4PZ7pehxm1l9OfNtTndM011xT8rd/0ddimNPXXHkrtfdJtuzN79mzTTtojqz0t2jN03333ufS86nGpdXae2K/tocepToD/6quvXLZ5+eWXy7Jly8yiw3njxo0zr7f2hDkPqysdknKUdV7cDYNpe2tdGzZsaHoMtddOe+ccQ7SeOL8vtBdV20Yn8yckJLgdpnP0sOlr5qC9Nvoc9NYTPQ70Pao91470Lzo1Qdva394b3ZbWXY8t5wtKtFdV73PQ56S9Rp56sUqivW7XXnutvPrqq3Lo0CG3ZfTYUM7Hi+OcpQpfaVua92hZtCfsE1yXiyGsTJ8+3QRK+uGnc2j0JOOcGkDpfY0bN3ZZp0M3+gFT+Gosx3CZ3u+gJyIdUtPLyDW40/lCOsTofCIuTPMe6dCSBgCFaR0dJ1THFUj6YeOurHIOSpTWwd0cr+Jo0KeLDgPpXDI9uerVbjrPQ+fc6IlV66AftIXniTno83XmHFg6f5AWnj/mq8Lb1cBQaZBdeL0GXVpnHXr2tQ31eCicq03rr3O6yooGTJpCJScnxwzXPfnkk+Y1cT5e9bjT51D4GHZ3XDqeh/McNB1i1/bQITGds6RfFBz0S4e389V0yEs/wDXw0y81CxYsKFKnkuixr8Nkc+fONe8b54DQ3Rwvx/3+5s/T4EjfcxpI6xCagw7Vv/3222bo2pf6Kx2q1mFqfb/oHD2l/9d5fI65p0rnEg4bNswco/qlReee6pcJDax88fDDD5tAV4Nid0PP+trrc3C+MlVp0K6BYOFjw9N7VL8oFs7PpvMo9dxSFu0J+xCEoczoSUJ7FUqiPUelOWFosKU9DNpbpPOMdJ6IBgHaQxAIGkzoh4/2vrlLF1C4Z6W43jdPdAK6frDqoh8kOgFe96kfIFqHkr7l6rdoZ+7qqQr3vviquO162p+vbVgW9dfgR3sQdKK2u1QLzgGTflDra6BBmX6wOad2KK2LLrrI3OpcRucgzBedOnUqqKv25mqwePPNN8u5555bJCB2Z9SoUSYA0/dLjx49zPtFXx/trXaXxNYRGGib+MNx3GpPqDvag1jS3MmS3vs611B76PQ1/eijj0wvpfN8O92nvqc0WNXgRefxaZCiPWg6d9NbGrRp76z2humcyOJ4G6h6Osa1J1nnoznTHmPtNS+r9oQ9CMIQdHTC+vLly4t8YGrPkON+Bz1RabCn34L1Q1NPrvrBpMFdcTRo0WBJe2gK2759u8vfeqWTnhh1P9qrVx4cgatj6EProO2hk/L9DfIKK89fBSiLNvS1/tpr4rhKUq/28+ZCCJ1crT0gmmNL96fHnfbGaaDi/MXB3XFZHMcQrfZiBYr2zmiQoQGJ9qJ6osP1GtzrhHDniwgKXyDhoG2mAVjhYN8bepWzDsVqwOR8tbKDDuVqUOFvEKZfVt5//33T064XMbibBN+gQQNzNagu2musE+e1rXwJwpQeC3qFb+GLThyvvR4Xek5xvsBFk1Nru3pzbBTuQdPh6MK9f2XZnrAHfZYIOtoTod3xL7/8sst6/VDUD8PCJ089IX3//fcmGad+Ky5pKNLxLVSHABcvXiz79u0rWK9XTOlcMWfaC6Ll9WRfuCdG/9b5NP7SeUfuOIZDdWjU8Y1X20PnjLn7UC/uw7MkmsFd+fNYX5VFG/paf+3xUd5mDtfeFJ3Po8eEIz2DHpd6Ja7zHERtf03kqb15ejWcJ0uWLCn4QA1kkKtX/+lVqYWvFHZHX4vCr4M+Bz3G3NFhckf7+ZqiQoNDDRxGjBhhgobCiw67axDlLqWJJxrsaK+gvh66aLDlfIWsPp/C9dMeZZ3q4M/+tJ21N0xT2RRuZz02lF4R7UyvBFaXXnqpT/vSOYLa2+m86HBlWbYn7EFPGIKODtPoN7mHHnrIXH6vH1g6lKAfhjqEoidDZxqk6DwbXXTehDdzazQg0EnSOlSh35AdH6aah8t57pHuS39qRoc8tS7ay6a9c9o7oCdETZGg+/V3HpL2Dunz1f3oyVV7vPSDWidZO4ar9MNde2Z0Ho/+TI+m1tB5VPqtW4dhdY6Ku2/FJdELGvTDWL/V6weV9hw6JvcGWlm0oW5T59poz49uS4MyvSCg8BCO83CS5h/T9i18IUFxdNK5zr/SNtI6az31A1jXa2Ci+Z60V+nbb781H76Fhzk1bYf2nCgdMtQvCpqiQucN6URvZ3r8OcoWpj1xjqCzOJq+RIfitR6eclrpB7XOb9JhSJ0gvmbNGtMuzqljHLTnSN8P+qHvTF83vQBFhzVLmpyvvTK63Z49e7q9X+fJafoHnbjuz7CvfuHS10iDFp0b5txDqT3pOsys7w09h2igrM9T5/w59wL6Qs9J2nbaY67nCgfdvvYu6nClfjHQ9+yPP/5oXm89dgLVM1XW7Qkb2HhlJsKUt5dFl5QpXFMJ3HXXXVbDhg3Npeht2rQx6QIcl2QXds4557i9RNzBXdbwr776yurWrZtJEdGyZUuTWqK4jPmalfrcc8819dWlXbt25tJ3TZPhbxbtt99+2xo6dKjVqlUrk7pDU2ZoFv2HHnrIJd2Bw6uvvmrqq2Vr1KhhderUybrvvvtMqgLny98vvfRSj2kn1KxZs8zzdqTlcKSrKC5FReFM7cW9zo421PQIgWpDPVac016oDz/80LSXpg/wJl3ClClTiqQuKSm7vXr00Udd2kbTNNxwww1W7dq1zXGjr4G7/RZONaFt3LhxY+uWW24p8msIJaWo0MWRCb2418GhV69eVlxcnJWcnFxiioqkpKSC56DtoWkwtm3bZtpX61I4G3/VqlWLHI/epKjQ56mvzbXXXltsGX0tdPtXXHGFXykVduzYUdBO33zzjct9mrLi3nvvtbp06WLeL3rM6f9nzJjhcbsl1cPxehU+TnNzc62JEydaLVq0MOcsTSGhqTQKpyTx5T1a3u2J8hel/9gR/AFAedIeP+0R0yvmHFfUoWSnnXaamQyuUwEABB5BGICIoUOLOoSmP4vEZfwl0+F6HcrT3FVlMUwNgCAMAADAFlwdCQAAYAOCMAAAABsQhAEAANiAIAwAAMAGYZ+sVX9K4uDBgyaRYnn+VAsAAIg8lmWZZMH66wyersIO+yBMAzBvftQWAAAgUPSH2PVXGyI6CHP8lIg2RlxcnN3VAQAAYSw1NdV0/hT+KbOIDMIcQ5AagBGEAQCA8uDNFCgm5gMAANiAIAwAAMAGBGEAAAA2CPs5Yd5eTnrixAnJy8uzuyoIQRUqVJCKFSuSAgUA4JOID8JycnLk0KFDkpmZ6VvLAU6qVq0qDRo0kMqVK9MuAACvRHQQpolc9+zZY3oyNKmafoCS0BW+9qJqIH/s2DFzLLVp08Zjcj4AACTSgzD98NRATPN5aE8G4I8qVapIpUqV5PfffzfHVGxsLA0JAPCIr+zaCPRcoJQ4hgAAviIIAwAAsAFBGAAAgA0IwgAAAGxAEFaMmTNnmh/f1PxhDunp6WYCdq9evVzKrlq1ylxVuWvXLvP3mjVrzBWXl156qdttL1q0SM4++2yJj483++jYsaOMGTPGpxfu+PHjUrNmTaldu7ZkZ2cXub958+amTrroRQedOnWS1157zdx3/fXXF9znbtHHeqJlpk2bVmT9o48+Kl27di34W68avP3226Vp06YSExMj9evXl379+sm3337rtq7Oy1NPPWXu37t3r8t6R5uNGDFCduzY4VV7PfbYYyaFxN9//+2y/ueffzb1+vjjj83fun2dWK+T7J0NHDjQtBsAAIFCEFaMCy+80ARd69atK1j39ddfmyDihx9+kKysrIL1X375pQkyWrVqZf6ePXu2jBo1SlavXi0HDx502e6KFStkyJAhMnjwYPnxxx9l/fr18sQTT0hubq5PL9z7779vApF27drJ4sWL3ZaZNGmSyYG2efNmueaaa+Tmm2+Wzz77TF544QWz3rGouXPnFvy9du1aCRR9nj/99JO8/vrr8ttvv8lHH31kgti//vrLbV2dF21DZ8uXLzfrNXB68sknZevWrdKlSxfTpp6MGzfOXAWrgZuDtvmwYcNM2/zjH/8oWK+B2COPPBKQ5w8AQHEiOkVFSdq2bWt6TrSXS3utlP7/8ssvl5UrV8r3339f0COm6zVoUxq4LVy40ARvhw8flnnz5smDDz5YsN0lS5bIOeecI/fee2/BulNOOcX0tPhCAz0NHjRPlf5fA7vCtMdIg0Z1//33yzPPPCPLli2TAQMGmF44ZwkJCQVlAyU5OdkErto+F1xwgVnXrFkzOeuss0qsa3Fq1apVUKZly5Zy2WWXyUUXXSTDhw83vZDa+1gczWj/xhtvyGmnnSbvvfeeXHnllSb41TpOnTrVpezIkSNlypQp5jU69dRT/Xz2AACUjCCsBBpYaS/XAw88YP7W/993333m5430/xqE6bCg9ozdeOONpsw777xjeqc0iNMgSYcZtRfGkQRWg4j58+eb3il/P+A14NAhzw8++MAEYXfddZcZPtMAxx3NhaZDoElJSeWa0b169epm0Z46DWR12C/QaSHuvPNOueKKK0yPorvgzpm+LpMnTzbDoxr06f+XLl0qcXFxLuU0SNZeO33dHcOUCA/6HkhLS/O6vL7XSwruC9PjKjEx0c/aAYg4VphLSUmx9GnqbWHHjx+3fv31V3PrzqxZs6xq1apZubm5VmpqqlWxYkXr6NGj1vz5863zzz/flFmxYoXZ/u+//27+7tmzpzVt2jTzf31c7dq1rS+//LJgm+np6dYll1xiHtOsWTNryJAh1uzZs62srCyvn9ODDz5oDRw4sODvyy+/3JowYYJLGd125cqVTf213rq/mjVrWjt27CiyPb1v0aJFXu/fsf2pU6cWWa/16NKlS8Hf7733npWYmGjFxsaathk3bpz1888/F1tX52X16tXm/j179pg6/vTTT0X2t3XrVnPfwoULvap3fn6+1atXLys6Otq68847i22LLVu2WBUqVCiog7bxsGHDit2up2MJ9vv777+t+IRE8xp7u0RFRftUXrev+wEQuVJKiDsKoyesBNrTlZGRYeZI6TdoHTasU6eOGVq74YYbzLwwHWrToTGdE7Z9+3Yzz0t7nRxDYDpMqMOFjqHLatWqySeffGJ6s7Q3TYc17777bjNPS3u3PGXu12/mOr9Kyztoj9s999xj5jE5Jw3V4TSdTK7zqPT/d9xxh7Ru3VrKk84J0wsUdFhSn6vOSdNhUb1IwHmiu6Ouzho1auRx+yfjppPzuLyh5R566CHzuj388MPFluvQoYNcd911pjfM+SIChC7tAUtJTpLR0xZIfO16Hsvv37FF5k4cKTc+/po0an5yvmdJUv48Ii+OGWr2Q28YAG8QhJVAA5bGjRubYEmDMMe8Jv2dSZ3k/d1335n7evfubdZrsKVXU+r9zkGCDsO9/PLLLvOwdBK/LjfddJMJCjTA07lkGtyV5PPPP5cDBw4UmQOmwZlOUL/44osL1umVk/ocdHn33XfNFZJnnHGGCTBKS4fwUlJSiqzXOVaF55vp1YZaL13Gjx9vnvOECRNcgi5HXX2lk/NVixYtvH6MBsfOt8WZOHGieV2Ku/ABoUkDsMS6//ceLSmoUnE163pVHgB8xdWRXswL014TXZxTU5x//vmmV0d7vrSMBl868fv555+XjRs3Fix6JZ8GZW+//Xax+9AUDdoDpr1unmigN3ToUJd96KLr9L7iaNCogZvOTwsEnfOm87AK27BhgwlcSqJBoDfP1ROd6/biiy+aAEwn3AeatplO0tcLKzTIBQAgkOgJ80ADLE1roOkMHD1hSv+vH9D6g81aRidwa2+ZXqlXuCdIh+Q0QLrttttMHq3MzEy55JJLzER67TnSQEK379yL5Y7m3NKrKzXNQ+FJ/Tp0phPUNQ+W5g9zRyex6+P0yk3tESsNvRjgvPPOM1cYDho0yAQpGmjqkOqMGTNMGU1D8a9//ctctNC5c2czaVn3rcORepWpMx3C0atJnWlg6jxpXrenZbT99MIGzVOmQbAO7/oyedoXGrTOmjVL9uzZ4/YKVAAA/EVPmAcaYOkVkDpUVq9ePZcgTAMHRyoLDbL69OlTJABzBGEafPzyyy/mcbt37zZBk16tp+kiNLD44osvzLZKoj1tOqdM0zIUpuuqVKkib775Zok9UH379g1IDqyePXuankBd9GpC7SXU4VkdEnUEiHplZPfu3U0KCO051PU6HKn5ynR41pnWSdvRedErUZ1p++p6HVbVuVrt27c3bepID1IWNKDV9B7OeeEAAAiEKJ2dL2EsNTXVBEY6f6lwKgL9YNUeDh3O0nlLgL84loLfvn37TO/z+De/9GqO195ffzIT7cfM+Eiati75C5JKOnpQHrvmQpMuRi/UARCZUkuIOwqjJwwAAMAGBGFBRn+KyJHktPDy1ltvlUsdNJ1EcXXQJVgFQ9sBAOAtJuYHmU8//bTY35F0npNWlnTSvl5xGWqCoe0AAPAWQViQKe6nh8qTTvAv76Su4dJ2AAB4i+FIAAAAGxCEAQAA2IAgDAAAwAYEYQAAADYgCAMAALABV0eGSSbwP//8s9z2V7t2bTKCAwBQSgRhIU4DsHbt28vxzMxy22eVqlVl29atXgdi119/vbz++usyefJk85uPDosXLzY/Oh7mv5wFAIBbBGEhTnvANAC7+v5npV7TVmW+vyP7dslbT99r9uvL7+Ppb3M+/fTTcuutt0piYmKZ1hEAgFBAEBYmNABr3KajBKs+ffrIzp07TW/YM888Y3d1AACwHRPzUS4qVKggTz75pLz00kuyf/9+Wh0AEPEIwlBudP5X165dZcKECbQ6ACDiMRyJcqXzwnr37i333HMPLQ8AKLWkpCRJS0vz6TE1atQIivnJBGEoV+eff77069dPxo0bZ66aBACgNAFYi5atJCU5yafHxSckyp7du2wPxAjCUO6eeuopMyzZtm1bWh8A4DftAdMAbPS0BRJfu55Xj0n584i8OGaoeSxBGAKWOiJU9tOpUye5+uqr5cUXXwxInQAAkS2+dj1JrNtQQg09YSFOs9dr8lTN3VVedH+639KYNGmSLFy4MGB1AgAg1BCEhThNmKrZ64P5Z4vmzZtXZF3z5s0lOzs7wDUDACB0EISFAQ2IfAmKAACA/cgTBgAAYAN6wgAggA4cOOBT+WDJVwSg/BGEAUAAHM/QZJFR0rNnz5DMVwSg/BGEAUAA5BzPFBFLbnz8NWnUvFXI5SsCUP4IwgAggOJq1g3JfEUAyh8T8wEAAGxAEAYAAGADgjAAAAAbMCcsDOzbty+oM+YDAICiCMLCIABr376dZGYeL7d9Vq1aRbZu3eZVIGZZllx88cVSoUIF+fzzz13umzFjhjz44IOyefNmady4cRnWGACA4EMQFuK0B0wDsDcf/Le0b1qnzPe3dd8xuebJd8x+vQnCoqKiZO7cudKpUyf573//K7feeqtZv2fPHrnvvvvklVdeIQADAEQkgrAwoQHY6ac0kmDUpEkTeeGFF2TkyJHSt29f8+Pdw4cPN/+/9tpr7a4eAAC2IAhDuRg2bJgsWrRIbrzxRhk0aJAZgtyyZQutDwCIWARhKDevvvqqdOzYUVavXi3vv/++1KlT9sOnAAAEK1JUoNzUrVvXzAlr3769DBw4kJYHAEQ0gjCUq4oVK5oFAIBIRxAGAABgA7okwoSmjgin/QAAEO4IwkKcZq/X5Kmau6u86P50vwAAwH8EYSFOE6Zq9vpQ+dmiRx991CwAAEQ6grAwoAERv+UIAEBoYWI+AABAJAdhTz31lPmdwTFjxhSsy8rKkhEjRkitWrWkevXqMnjwYDly5Iit9QQAAAibIGzt2rXmx507d+7ssv6uu+6SJUuWyLvvvitfffWVHDx40PzkDQAAQKizPQhLT0+Xq6++WmbNmiWJiYkF61NSUmT27NkyZcoU6d27t3Tr1k3mzp0r3333nXz//fcBrYNlWQHdHiIPxxAAIOSCMB1uvPTSS6VPnz4u69evXy+5ubku69u1a2cmoK9Zs6bY7WVnZ0tqaqrLUpxKlSqZ28zMzIA8F0QuxzHkOKYAAAjqqyMXLFggGzZsMMORhR0+fFgqV64sCQkJLuvr1atn7ivO5MmTZeLEiV7tv0KFCmb7R48eNX9XrVrVzEsDfOkB0wBMjyE9lvSYAgAgqIOwP/74Q+68805ZtmyZxMbGBmy748aNk7Fjxxb8rT1hTZo0KbZ8/fr1za0jEAP8oQGY41gCACCogzAdbtTA5/TTTy9Yl5eXJ6tXr5aXX35ZPv/8c8nJyZHk5GSX3jC9OrKkD7uYmBizeEt7vho0aCB169Y1w5+Ar3QIkh4wAEDIBGEXXXSRbNq0yWXdDTfcYOZ93X///ab3Sj/cVqxYYVJTqO3bt8u+ffukR48eAa+PfojyQQoAAMI+CKtRo4aceuqpLuuqVatmcoI51g8fPtwMLdasWVPi4uJk1KhRJgA7++yzbao1AABABPxs0dSpUyU6Otr0hOlVj/369ZMZM2bYXS0AAIDwCsJWrVrl8rdO2J8+fbpZAAAAwontecIAAAAiEUEYAACADQjCAAAAbEAQBgAAYAOCMAAAABsQhAEAANiAIAwAAMAGBGEAAAA2IAgDAACwAUEYAACADQjCAAAAbEAQBgAAYAOCMAAAABsQhAEAANiAIAwAAMAGBGEAAAA2IAgDAACwAUEYAACADQjCAAAAbEAQBgAAYAOCMAAAABsQhAEAANiAIAwAAMAGBGEAAAA2IAgDAACwAUEYAACADQjCAAAAbEAQBgAAYAOCMAAAABsQhAEAANiAIAwAAMAGBGEAAAA2IAgDAACwAUEYAACADQjCAAAAbEAQBgAAYAOCMAAAABsQhAEAANiAIAwAAMAGBGEAAAA2IAgDAACwAUEYAACADQjCAAAAbEAQBgAAYAOCMAAAABsQhAEAANigoh07BQAAcCcpKUnS0tLEGwcOHDC3aalpEh2T4tVjtGywIAgDAABBE4C1atlCkpK9C6gcZs+ZLdEx1bwqm5+dYW5TUnzbR1kgCAMAAEEhLS3NBGDfvXSbNKod57H80h9/k1unLpZB57SX5s2aeLWPAwcPy2vrPpT09HSxG0EYAAAIKo1qx0nTegkey9VJONn7VbVKJYmvHuvVtlOqVJZgwcR8AAAAGxCEAQAA2IAgDAAAwAYEYQAAADYgCAMAALABQRgAAIANCMIAAABsQBAGAABgA4IwAAAAGxCEAQAA2IAgDAAAwAYEYQAAADYgCAMAALABQRgAAIANCMIAAABsQBAGAABgA4IwAACASAvCXnnlFencubPExcWZpUePHvLZZ58V3J+VlSUjRoyQWrVqSfXq1WXw4MFy5MgRO6sMAAAQ+kFY48aN5amnnpL169fLunXrpHfv3nL55ZfLli1bzP133XWXLFmyRN5991356quv5ODBgzJo0CA7qwwAABAQFcVGl112mcvfTzzxhOkd+/77702ANnv2bJk/f74JztTcuXOlffv25v6zzz7bploDAACE0ZywvLw8WbBggWRkZJhhSe0dy83NlT59+hSUadeunTRt2lTWrFlT7Hays7MlNTXVZQEAAAg2tgdhmzZtMvO9YmJi5LbbbpNFixZJhw4d5PDhw1K5cmVJSEhwKV+vXj1zX3EmT54s8fHxBUuTJk3K4VkAAACEWBDWtm1b2bhxo/zwww9y++23y7Bhw+TXX3/1e3vjxo2TlJSUguWPP/4IaH0BAABCfk6Y0t6u1q1bm/9369ZN1q5dKy+88IIMGTJEcnJyJDk52aU3TK+OrF+/frHb0x41XQAAAIKZ7T1hheXn55t5XRqQVapUSVasWFFw3/bt22Xfvn1mzhgAAEAos7UnTIcOBwwYYCbbp6WlmSshV61aJZ9//rmZzzV8+HAZO3as1KxZ0+QRGzVqlAnAuDISAACEOluDsKNHj8p1110nhw4dMkGXJm7VAOziiy8290+dOlWio6NNklbtHevXr5/MmDHDzioDAACEfhCmecBKEhsbK9OnTzcLAABAOAm6OWEAAACRgCAMAADABgRhAAAANiAIAwAAsAFBGAAAgA0IwgAAAGxAEAYAAGADgjAAAAAbEIQBAADYgCAMAADABgRhAAAANiAIAwAAsAFBGAAAgA0IwgAAAGxAEAYAAGCDinbsFABKKykpSdLS0rwuf+DAARodCBEH/kz1qtyx5AyJuCCsZcuWsnbtWqlVq5bL+uTkZDn99NNl9+7dgaofALgNwFq0bCUpyUk+t052dhYtCgSplJQUEYmSnqNm+vS4nJw8iZggbO/evZKXV/QJZ2dn820TQJnTHjANwEZPWyDxtet59Zj9O7bI3IkjJSc7t8zrB8A/6enpImLJjaPvlkYNPL+3N27aKkvmz5UTefnhH4R99NFHBf///PPPJT4+vuBvDcpWrFghzZs3D2wNAaAYGoAl1m3oVfuk/HmEdgRCRFx8giQWGm1zp1r1GhLKfArCBg4caG6joqJk2LBhLvdVqlTJBGDPP/98YGsIAAAQhnwKwvLzT3b3tWjRwswJq127dlnVCwAAIKz5NSdsz549ga8JAABABPE7RYXO/9Ll6NGjBT1kDnPmzAlE3QAAAMKWX0HYxIkTZdKkSXLGGWdIgwYNzBwxAIB/fMlhVqNGDUlMTKSpgUgNwmbOnCnz5s2Ta6+9NvA1AoAIcTxDk81GSc+ePb1+THxCouzZvYtADIjUICwnJ8enkwYAwM259HjmyZxIj78mjZq38irNxotjhpo8afSGAREahN10000yf/58GT9+fOBrBAARJq5mXa/znQGI8CAsKytLXn31VVm+fLl07tzZ5AhzNmXKlEDVDwAAICz5FYT98ssv0rVrV/P/zZs3u9zHJH0AAIAyCsK+/PJLfx4GAACA/4l2/AcAAABB3hN24YUXljjsuHLlytLUCQBCVnpGmqSkpHhXNj2jzOsDIMyCMMd8MIfc3FzZuHGjmR9W+Ie9ASAS5ORkm9uFC9+R6JhqXj3mROoxc5v9v8cCiCx+BWFTp051u/7RRx+V9PT00tYJAEJOTs4Jc3vZ2e2kTcumXj1m+7btsmDTMsnNzSnj2gEIq9+OdOeaa66Rs846S5577rlAbhYAQkbV2MoSXz3Wy7Ku6X0ARJaATsxfs2aNxMZ6d/IBAACIZH71hA0aNMjlb8uy5NChQ7Ju3Tqy6AMAAJRVEBYfH+/yd3R0tLRt21YmTZokffv29WeTAAAAEcWvIGzu3LmBrwkAAEAEKdXE/PXr18vWrVvN/zt27CinnXZaoOoFAAAQ1vwKwo4ePSpDhw6VVatWSUJCglmXnJxskrguWLBA6tSpE+h6AgAAhBW/ro4cNWqUpKWlyZYtW+Tvv/82iyZqTU1NldGjRwe+lgAAAGHGr56wpUuXyvLly6V9+/YF6zp06CDTp09nYj4AAEBZ9YTl5+dLpUpFkwzqOr0PAAAAZRCE9e7dW+688045ePBgwboDBw7IXXfdJRdddJE/mwQAAIgofgVhL7/8spn/1bx5c2nVqpVZWrRoYda99NJLga8lAABAmPFrTliTJk1kw4YNZl7Ytm3bzDqdH9anT59A1w8AACAs+dQTtnLlSjMBX3u8oqKi5OKLLzZXSupy5plnmlxhX3/9ddnVFgAAIBKDsGnTpsnNN98scXFxbn/K6NZbb5UpU6YEsn4AAABhyacg7Oeff5b+/fsXe7/+bqRm0QcAAEAAg7AjR464TU3hULFiRTl27JgvmwQAAIhIPgVhjRo1Mpnxi/PLL79IgwYNAlEvAACAsOZTEHbJJZfI+PHjJSsrq8h9x48flwkTJsg//vGPQNYPAAAgLPmUouLhhx+WDz74QE455RQZOXKktG3b1qzXNBX6k0V5eXny0EMPlVVdAQAAIjMIq1evnnz33Xdy++23y7hx48SyLLNe01X069fPBGJaBgAABL+kpCRJS0vzunyNGjUkMTGxzPZx+PBhiSQ+J2tt1qyZfPrpp6ZRd+7caQKxNm3a+PyiAAAA++jneIuWrSQlOcnrx8QnJMqe3bu8/sz3Zx8qO/eERAK/MuYrfQE0QSsAAAg92julwdHoaQskvrbnUayUP4/Ii2OGmsd5G4T5uo/tG3+Ud567X3JP5Esk8DsIAwAAoU+Do8S6DYNiH9UTaksk8esHvAEAAFA6BGEAAAA2IAgDAACwAUEYAACADQjCAAAAbEAQBgAAYAOCMAAAABsQhAEAANiAIAwAACDSgrDJkyebnz7SHwStW7euDBw4ULZv3+5SJisrS0aMGCG1atWS6tWry+DBg+XIkSO21RkAACDkg7CvvvrKBFjff/+9LFu2THJzc6Vv376SkZFRUOauu+6SJUuWyLvvvmvKHzx4UAYNGmRntQEAAEL7tyOXLl3q8ve8efNMj9j69evl/PPPl5SUFJk9e7bMnz9fevfubcrMnTtX2rdvbwK3s88+26aaAwAAhNEPeGvQpWrWrGluNRjT3rE+ffoUlGnXrp00bdpU1qxZ4zYIy87ONotDampqudQdAMrLgQMHvC6r0z0SExPLtD6AJ2mpaRIdc/IzviSZmekR1ZhBE4Tl5+fLmDFj5JxzzpFTTz3VrDt8+LBUrlxZEhISXMrWq1fP3FfcPLOJEyeWS50BoDwdz0gTkSjp2bOn14+JT0iUPbt3EYjB1s6V2XNmS3RMNY/lT6QeM7d5eSckEgRNEKZzwzZv3izffPNNqbYzbtw4GTt2rEtPWJMmTQJQQwCwV87xTBGx5MbHX5NGzVt5LJ/y5xF5ccxQSUtLIwiDLdLTT/ZsDenVWRo1rO+x/MafN8uHm5ZJfr4lkSAogrCRI0fKxx9/LKtXr5bGjRsXrK9fv77k5ORIcnKyS2+YXh2p97kTExNjFgAIV3E160pi3YZ2VwPwWvUqlSW+eqzHclViKkVUq9p6daRlWSYAW7RokaxcuVJatGjhcn+3bt2kUqVKsmLFioJ1msJi37590qNHDxtqDAAAEAY9YToEqVc+fvjhh2byqGOeV3x8vFSpUsXcDh8+3Awv6mT9uLg4GTVqlAnAuDISAACEMluDsFdeecXc9urVy2W9pqG4/vrrzf+nTp0q0dHRJkmrXvXYr18/mTFjhi31BQAACIsgTIcjPYmNjZXp06ebBUBgJCUlmcnavvA11YGv+8jLy5MKFSoEPEUDAASroJiYD6D8aHDUomUrSUlO8ulxvqQ68GcfUVHRYln5PtUpOzvLp/IAEEwIwoAIo71TGhyNnrZA4mvX8+oxvqY68HUf+3dskbkTR3qdesFRPic716v6A0AwIggDIpQGR2Wd5sDbfWiQ50vqBUd5AAhltqaoAAAAiFQEYQAAADYgCAMAALABQRgAAIANmJgPADbLzDguKSkpHsulp2eUS318zfHmaw45ACcRhAGATXJy88ztko+XSPSylR7Ln0g9Zm6zc7LLrE7+5HjzJYccgP9DEAYANjmRdzI5bf8zW0mHNp7zo23ftl0WbFomubk5ZVYnX3O8+ZpDDsD/IQgDAJtVrVxZ4qvHei4XW0nCKY8cEOmYmA8AAGADgjAAAAAbEIQBAADYgCAMAADABkzMBwCU2oEDB4Iqrxi5zhAKCMIAAH47nqFJXaOkZ8+eQZNXjFxnCBUEYQAAv+UczxQRS258/DVp1LxVUOQVI9cZQgVBGACg1OJq1g26vGLkOkOwY2I+AACADQjCAAAAbEAQBgAAYAOCMAAAABswMR8IQsGa48jbXFC+5IxCZPL1GCmvYzwS39dpqWkSHZPiVTlfX7vDhw+Xqm7hjiAMCDLBmOPIn1xQKjs7q0zqg9Dl77FU1sd4JL6vU1JOBl6z58yW6JhqHsvnZST59dqp7NwTftUx3BGEAUEmGHMc+ZoLav+OLTJ34kjJyc4tk/ogdPl6LJXXMR6J7+v09HRzO6RXZ2nUsL7H8tu3bZcFGz+ToQ++KG06dPJqH9s3/ijvPHe/5J7IL3V9wxFBGBCkgjHHkbe5oPQDBAjEsRRugvF9Xb1KZYmvHuuxXNXYSifLJ9by+jlUT6hd6vqFMybmAwAA2IAgDAAAwAYEYQAAADYgCAMAALABE/MBoATpGWkFl/KXJDPz5JVmQCBFYj61SEIQBgBu5ORkm9uFC9/xKofSidRj5jYvj3xIKL1IzacWaQjCAMCNnJyTwdRlZ7eTNi2bemyjjT9vlg83LZP8fIv2RKlFaj61SEMQBgAlqBrrXQ6lKjEncygBgRSp+dQiBRPzAQAAbEAQBgAAYAOCMAAAABsQhAEAANiAifkAIgp5vyJHWmqaRMekeFXOH0lJSeZKxLLI94XIQBAGICKQ9ytyOJLrzp4z26scb/nZGS6P8zYAa9GylaQkJ/lUt+zsLJ/KI7wRhAGICOT9ihzp6Sd/vWBIr87SqGF9j+UPHDwsr637sOBx3tAeMA3ARk9bIPG163ksv3/HFpk7caTkZOd6vQ+EP4IwABGFvF+Ro3oV73K8pVSp7Pc+NADzJo+XJlIFCmNiPgAAgA0IwgAAAGxAEAYAAGAD5oQBQJjzJT0CqRTKJg1GevrJKzABZwRhABCmjmdoDqso6dmzp8+PJZVCYNNgnEg9drJdc7J9fi0QvgjCACBM5RzPFBFLbnz8NWnUvJVXjyGVQtmkwdi+bbss2LRMcnNzvNwDIgFBGACEubiadb1Ko6BIpVA2aTCqxlbyccuIBEzMBwAAsAFBGAAAgA0IwgAAAGxAEAYAAGADJuYDCBrpGWkFl/6XWI6cSwDCAEEYANvl/C930sKF75BzCUDEIAgDYLucnBPm9rKz20mblk09lifnEoBwQBAGIGhUjSXnEoDIwcR8AAAAGxCEAQAA2IAgDAAAwAYEYQAAADZgYj7CSlJSkqSlpfn0mBo1akhiYmKZ1SmcBFser8yM417Vx5TNTC/z+kSyYDs2Itn69evlwIEDHstt2rSpXOqD4hGEIawCsBYtW0lKcpJPj4tPSJQ9u3cRiIVQHq+c3Dxzu+TjJRK9bKVXj3HUKS/vZDoMhOexEclS/ta2jZJBgwb59LjMLF4LuxCEIWxoD5gGYKOnLZD42vW8ekzKn0fkxTFDzWPpDQudPF4n8vLNbf8zW0mHNq28eszGnzfLh5uWSX6+VSZ1ilTBdmxEsvRUHQWw5PJht0mLpo08lt/y6zZZ9v5bkv2/1xDljyAMYUcDsMS6De2uRlgKtjxeVSt7Vx9VJaZ86hSpgu3YiGR16tSRpk08nwMPHznZKwn7MDEfAAAg0oKw1atXy2WXXSYNGzaUqKgoWbx4scv9lmXJI488Ig0aNJAqVapInz59ZMeOHbbVFwAAICyCsIyMDOnSpYtMnz7d7f3PPPOMvPjiizJz5kz54YcfpFq1atKvXz/Jysoq97oCAACEzZywAQMGmMUd7QWbNm2aPPzww3L55ZebdW+88YbUq1fP9JgNHTq0nGsLAAAQARPz9+zZI4cPHzZDkA7x8fHSvXt3WbNmTbFBWHZ2tlkcUlNTy6W+sD/vlzd5cYBI5G0OL1OWPF5AuQnaIEwDMKU9X870b8d97kyePFkmTpxY5vVD8Ob9ys5muBrwJ4eXIo8XUH6CNgjz17hx42Ts2LEuPWFNmjSxtU4on7xf+3dskbkTR0pOdi5NDviRw0uRxwsoP0EbhNWvX9/cHjlyxFwd6aB/d+3atdjHxcTEmAWRl/dLE68C8D+H18my5PECJNLzhLVo0cIEYitWrHDp1dKrJHv06GFr3QAAAEK6Jyw9PV127tzpMhl/48aNUrNmTWnatKmMGTNGHn/8cWnTpo0JysaPH29yig0cONDOagMAAIR2ELZu3Tq58MILC/52zOUaNmyYzJs3T+677z6TS+yWW26R5ORkOffcc2Xp0qUSG+tdtzoAAECwsjUI69Wrl8kHVhzNoj9p0iSzAAAAhJOgnZgPRGKus/LMd5aWmibRMd7ljsrMTPdrH5kZx73KT+Xv9oFA0vRH+/bt87pssOV4430UegjCgCDMdVaW+c4cJ/TZc2b7nDsqL+9kygNPcnLzzO2Sj5dI9LKVAd8+EEhZx4/r2IsMGjTI58dm554IuhxvvI9CB0EYEES5zsoj35leEKOG9OosjRqeTAXjycafN8uHm5ZJfn7x0wecncjLN7f9z2wlHdq0Cvj2gcAHPJYMffBFadOhk1eP2b7xR3nnufsl98TJYz0YcrzxPgo9BGFAEOU6K898Z9WreJ87qkqMf7mjqlb2bh/+bh8IpOqJtbx+n1ZPqB10Od54H4WeoM0TBgAAEM4IwgAAAGxAEAYAAGAD5oSh3FIvqBo1akhiYmLEPO/ySjeh1q9f79X+Nm3aVC71QdkJh9Qf3j4HRzoVX95P5ZU+AigtgjD4HYi0atlCkpK9O4k6JCbEy67de0I2EPM35URZpZtQKX8f8+vy+sysk5fAI3SEQ+oPX5+DysvQ91uU9OzZMyjSRwCBQhAGv2hPkAZg3710mzSqHefVYw78mSo9R800jw3VIMzXlBNlnW5CpZteAksuH3abtGjayGP5Lb9uk2XvvyXZ/7sEHqEjHFJ/+Poc1PZt22XBxs+8TiFR1ukjgEAhCEOpaADWtF5CxLWityknyivdhKpTp440beK5ToePnOwdQegKh9Qf3j4HUza2kk8pJMorfQRQWkzMBwAAsAFBGAAAgA0IwgAAAGxAEAYAAGADJuYj6GmOoOgYz6kw0tMzyjzHFvmHECmCMRdZMNYpEvmS443XomQEYQhajjf57DmzJTqmmtc5kbJzsss8x1ZqaorXP/QLhJJgzEUWjHWKRP7keOO1KBlBGIJWevrJb7NDenWWRg3re5dLaNMyyc3NKbMcW7t27ZYl8+dKRob/vW5AMAvGXGTBWKdI5E+ON16LkhGEIehVr+JdPiFHLqGyzLGVmpLs9z6AUBKMuciCsU6RyJccb7wWJWNiPgAAgA0IwgAAAGxAEAYAAGADgjAAAAAbMDEf5c6bfFyKnFwAgHBGEIZyk5KeJdFRIj179vTpcSfI9QMACEMEYSg36Vk5oml7vph8jbRt7jkdxNIff5Nbpy6WvPyTuWkAAAgnBGEodw1q1ZCm9RI8lquT4DlLPgAAoYqJ+QAAADYgCAMAALABQRgAAIANCMIAAABswMT8EJGUlCRpaWk+PSYvL08qVKjgdfkaNWpIYmKihLrMjOOSkpLiXdnM9DKvDwAA7hCEhUgA1qJlK0lJTvLpcVFR0WJZ3qd3SEyIl12794RsIJaTm2dul3y8RKKXrfTqMSdSj5nbPHKRAQDKGUFYCNAeMA3ARk9bIPG163n1mAN7d8mch2+SDyZeLd1OaeS5/J+p0nPUTLOvUA3CTuSdDDj7n9lKOrRp5dVjNv68WT7ctEzyNYEZAADliCAshGgAlljXc5JTlZZ6cuiyfk3vcnKFk6qVK0t89VivylaJqVTm9QEAwB0m5gMAANiAIAwAAMAGBGEAAAA2IAgDAACwARPzQyDv14EDB/zez+G/02TfkWTP+/gz1ad9laZOkSg9I83r3GXp6Rk+PYZcZ0Do5Bj0dh+8ryMDQVgI5f3Kzs7yumyWOUFEyaAJb3m/g6go6dmzp091yvKhTpEoJyfb3C5c+I5Ex1TzKXeZt48h1xkQ/DkGfd0H7+vIQBAWAnm/9u/YInMnjpSc7Fyv95GTdVxELBl6y2hp06Kxx/I79uyXBa++KG/ef4Wc17WNx/LrfztgArycHO/rFIlyck6eoC87u520adnUp9xl3uY7I9cZEPw5Bn3dB+/ryEAQFgJ5v1L+POL3PqrHxUtirVqey/11cmi0bkI1r/KKOYYv4Z2qsb7nLvM23xm5zoDQyTHI+xrOmJgPAABgA4IwAAAAGxCEAQAA2IA5YSGWcqKsHU3O8Cqlhaa+8Nehv9IkrobnfRxLPpmqIRhxmTkAoLQIwgIUgLVq2UKSkr3LL+NPyomylm2upoySa55e5MOjoiQl42QKBm+kZmrZKOk77k2f6paTc/LS7mDAZeYAgEAhCAsA7QHTAOy7l26TRrXjvE/v4EPKibKWm5NjUloMvuF26XBKC69TWmRm6eO8c7KsJdfePlqaN/WcNmPjpq2yZP7cgku7gwGXmQMAAoUgLIA0AAv19A6+prTwax/x3u2jWvUaEqy4zBwAUFpMzAcAALABQRgAAIANCMIAAABsQBAGAABgAybmB5C3E+5Lk2MrVPOKBXveLwAAyhtBWACkpGh+sCjpOWqmT4/LzvE+x1aw8S+vWPDl/QIAwC4EYQGQnp5u8l/dOPpuadSgnsfy23/bIe/MnSW5ud7n2Ao2vuYVC9a8XwAA2IUgLIDi4hO8y7FV44iEC2/zigV73i8AAMobE/MBAABsQBAGAABgA4IwAAAAGxCEAQAA2ICJ+TbKzDj+v/QWJUtPJ78WAADhhiDMBjm5J/NkLfl4iUQvW+mx/InUYyGfVwwAALgiCLOBI09W/zNbSYc2rTyW375tuyzYtCyk84oBAABXBGE2qlq5ssRXj/VcLrZSudQHAACUHybmAwAA2CAkgrDp06dL8+bNJTY2Vrp37y4//vij3VUCAAAI7yBs4cKFMnbsWJkwYYJs2LBBunTpIv369ZOjR4/aXTUAAIDwDcKmTJkiN998s9xwww3SoUMHmTlzplStWlXmzJljd9UAAADCc2J+Tk6OrF+/XsaNG1ewLjo6Wvr06SNr1qxx+5js7GyzODjycKWmppZZPTMyTubx+uOP/ZKdneWx/JHDh83toUMHpWpMBY/lDx46Wf7gnp1SKdpzeVP29x0nbw8ckErR+QGvk6/ly2Mf1Cly2ikcngN1op04nux53x09+mfBZ3dZxAaObVqW5bmwFcQOHDigz8D67rvvXNbfe++91llnneX2MRMmTDCPYaENOAY4BjgGOAY4BjgGxKY2+OOPPzzGOUHdE+YP7TXTOWQO+fn58vfff0utWrUkKipKQo1G1E2aNJE//vhD4uLiJNLRHrQFxwbvFc4bnEeD+TNFe8DS0tKkYcOGHssGdRBWu3ZtqVChghw5csRlvf5dv359t4+JiYkxi7OEhAQJdXpwEITRHhwbvFc4d3Ae5XMl+D9j4+PjQ39ifuXKlaVbt26yYsUKl54t/btHjx621g0AAKA0gronTOnQ4rBhw+SMM86Qs846S6ZNm2Ym0+nVkgAAAKEq6IOwIUOGyLFjx+SRRx6Rw4cPS9euXWXp0qVSr149iQQ6tKo50goPsUYq2oO24NjgvcJ5g/NouHymROnsfFv2DAAAEMGCek4YAABAuCIIAwAAsAFBGAAAgA0IwgAAAGxAEBYENKP/1VdfbRLFaWLZ4cOHS3p6erHl9+7da7L/u1vefffdgnLu7l+wYIGEU1uoXr16FXmet912m0uZffv2yaWXXmp+/L1u3bpy7733yokTJyTY+doeWn7UqFHStm1bqVKlijRt2lRGjx5d8BuqoXRsTJ8+XZo3by6xsbHSvXt3+fHHH0ssr8d+u3btTPlOnTrJp59+6nK/XoOkV1k3aNDAtI3+Bu2OHSd/YzUU+NIes2bNkvPOO08SExPNos+1cPnrr7++yDHQv39/Ccf2mDdvXpHnqo8Ll+PDl7Zwd77URc+PoX5srF69Wi677DKTqV7rvHjxYo+PWbVqlZx++unm6sjWrVubY6W05yKfBOp3HuG//v37W126dLG+//576+uvv7Zat25tXXXVVcWWP3HihHXo0CGXZeLEiVb16tWttLS0gnL68s6dO9el3PHjx8OqLdQFF1xg3XzzzS7PMyUlxaW9Tj31VKtPnz7WTz/9ZH366adW7dq1rXHjxlnBztf22LRpkzVo0CDro48+snbu3GmtWLHCatOmjTV48GCXcsF+bCxYsMCqXLmyNWfOHGvLli3m9U1ISLCOHDnitvy3335rVahQwXrmmWesX3/91Xr44YetSpUqmfZweOqpp6z4+Hhr8eLF1s8//2z985//tFq0aBFUzztQ7fGf//zHmj59ujnet27dal1//fXmue/fv7+gzLBhw8zx5XwM/P3331Yo8LU99FiPi4tzea6HDx92KROqx4evbfHXX3+5tMPmzZvNe0fbKNSPjU8//dR66KGHrA8++MCc4xYtWlRi+d27d1tVq1a1xo4da84bL730kmmLpUuX+t2+viIIs5m+8HqwrF27tmDdZ599ZkVFRZkfMPdW165drRtvvNFlnTcHYTi0hQZhd955Z4lvzOjoaJeT7iuvvGJOytnZ2Va4HxvvvPOOOYnk5uaGzLFx1llnWSNGjCj4Oy8vz2rYsKE1efJkt+X//e9/W5deeqnLuu7du1u33nqr+X9+fr5Vv35969lnny24Pzk52YqJibHefvttK9j52h6F6ReRGjVqWK+//rrLB+3ll19uhSJf20MDDA2wihPKx0dpj42pU6eaYyM9PT0sjg1fznH33Xef1bFjR5d1Q4YMsfr16xew9vWE4UibrVmzxgwz6S8COGg3eHR0tPzwww9ebWP9+vWyceNGM1RV2IgRI8xvcOqvDcyZM8d0uYdjW7z11lvmeZ566qnmR9wzMzNdtqvDU84Jfvv162d+uHXLli0SzseG0qFIHc6sWLFiSBwbOTk55pjW5+qgz1n/1jZxR9c7l3e8xo7ye/bsMcmencvob7vp0EJx2wwW/rRHYfp+yM3NlZo1axYZitHheR2+vv322+Wvv/6SYOdve+gwfrNmzcyPNV9++eUu7/1QPT4CcWzMnj1bhg4dKtWqVQv5Y8NXns4bgWjfkM+YH+70ja8HujP9sNSTpd7n7Zuoffv20rNnT5f1kyZNkt69e5t5UF988YXccccd5kSkc4TCqS3+85//mJOrzgP45Zdf5P7775ft27fLBx98ULDdwr+w4Pjb2zYO1WPjzz//lMcee0xuueWWkDk2tM55eXluX7Nt27a5fUxxr7GjnRy3JZUJVv60R2H6ntD3h/OHic7xGTRokLRo0UJ27dolDz74oAwYMMB8uFSoUEHCqT00kNAvGp07dzZfSp577jlzvtRArHHjxiF7fJT22NC5TZs3bzafIc5C9djwVXHnDf2Cfvz4cUlKSir1e88TgrAy8sADD8jTTz9dYpmtW7eWej96oMyfP1/Gjx9f5D7ndaeddpr5zc1nn3223D9oy7otnAMM7fHSibUXXXSROXm0atVKIvXY0BOJTrbt0KGDPProo0F5bKDsPfXUU+aiC+3ZcJ6Mrr0fzu8bDVD0/aLl9P0TTnr06GEWBw3A9Ivrf//7X/MlJVJp8KWvvfaGO4ukY8NuBGFl5O677zZXmJSkZcuWUr9+fTl69KjLer1qT69y0/s8ee+998xQw3XXXeexrHat6wknOzu7XH8nq7zawvl5qp07d5oThz628NUsR44cMbe+bDeU2iMtLc18m61Ro4YsWrRIKlWqFJTHhjs6RKrfth2vkYP+Xdzz1vUllXfc6joN0p3L6O/RBjN/2sNBe3w0CFu+fLn5IPV0zOm+9H0TzB+0pWkPB30/6JcPfa6hfHyUpi30i5cG59or7kmoHBu+Ku68odM39ApZbdvSHmueMCesjNSpU8dcLl/SUrlyZfPtLDk52Yw7O6xcuVLy8/MLgglP32T++c9/mv15ovPG9HL18v6QLa+2cH6eynEy1e1u2rTJJaBZtmyZeaNpL1F5K+v20B6wvn37mm189NFHRS7FD6Zjwx2td7du3WTFihUF6/Q569/OvRnOdL1zecdr7Civwyp60nQuo+2kc+uK22aw8Kc91DPPPGMC66VLl7rMKyzO/v37zbwf5yAknNrDmQ4x6TnB8VxD9fgoTVtoShf90nXNNdeEzbHhK0/njUAcax4FZHo/SkUvBT7ttNOsH374wfrmm29MSgHnNAR6WXnbtm3N/c527NhhrpTTK+YK0xQFs2bNMpfoa7kZM2aYS3EfeeSRsGoLTcMwadIka926ddaePXusDz/80GrZsqV1/vnnF0lR0bdvX2vjxo3m8uM6deqETIoKX9pDU3PoVYGdOnUybeN8ibm2Q6gcG3pZuF6ZNm/ePHOV6C233GIuC3dc4XrttddaDzzwgEuKiooVK1rPPfecSckwYcIEtykqdBt6jPzyyy/m6q9QSEHgT3voc9UrYt977z2XY8CRwkZv77nnHmvNmjXmfbN8+XLr9NNPN8dXVlaWFW7toSl8Pv/8c2vXrl3W+vXrraFDh1qxsbEm5UCoHx++toXDueeea64ELCyUj420tDSTlkUXDW+mTJli/v/777+b+7UdtD0Kp6i49957zXlD07q4S1FRUvuWFkFYENC8LfrBqnm+NG3CDTfc4JLvS98IekB9+eWXLo/TIKJJkybmktnCNDDTtBW6zWrVqplcUzNnznRbNpTbYt++fSbgqlmzpnmjaB4tfUM55wlTe/futQYMGGBVqVLF5Ai7++67XVI2hEt76K3+7W7RsqF0bGjOnqZNm5pgQi8T11xpzmlJ9DL6wqk4TjnlFFNeLzv/5JNPiqQhGD9+vFWvXj1zrFx00UXW9u3brVDhS3s0a9bM7TGgwanKzMw0X0r0y4gGq1pe8x8F6oMl2NpjzJgxBWX19b/kkkusDRs2hM3x4et7Zdu2beZ4+OKLL4psK5SPjS+LOf85nr/eansUfoyeD7Xt9Au8c740b9q3tKL0n8D0qQEAAMBbzAkDAACwAUEYAACADQjCAAAAbEAQBgAAYAOCMAAAABsQhAEAANiAIAwAAMAGBGEAAAA2IAgDAD9ERUXJ4sWLaTsAfiMIA1Cu1qxZIxUqVJBLL720yH179+41wU3hxZsfGS4rjz76qHTt2rXI+kOHDsmAAQPEbvPmzZOEhAS7qwHADxX9eRAA+Gv27NkyatQoc3vw4EFp2LBhkTLLly+Xjh07FvxdpUqVoGvw+vXr210FACGOnjAA5SY9PV0WLlwot99+u+kJ014cd2rVqmWCHMcSHx9f7DZnzJghbdq0kdjYWKlXr55ceeWVBffl5+fL5MmTpUWLFiaQ69Kli7z33nsF969atcr0tK1YsULOOOMMqVq1qvTs2VO2b99u7tf6TZw4UX7++eeCXjlHnZ2HIx09eO+8846cd955Zl9nnnmm/Pbbb7J27Vqz7erVq5ues2PHjrnU/7XXXpP27dub+rdr1848HwfHdj/44AO58MILTf30OWhvoqP+N9xwg6SkpBTUT3vuAISIgP0UOAB4MHv2bOuMM84w/1+yZInVqlUrKz8/v+D+PXv2WHpa+umnn7xqy7Vr11oVKlSw5s+fb+3du9fasGGD9cILLxTc//jjj1vt2rWzli5dau3atcuaO3euFRMTY61atcrc/+WXX5r9de/e3azbsmWLdd5551k9e/Y092dmZlp333231bFjR+vQoUNm0XVKH7do0SKXejv29euvv1pnn3221a1bN6tXr17WN998Y+rWunVr67bbbiuo35tvvmk1aNDAev/9963du3eb25o1a1rz5s0rst2PP/7Y2r59u3XllVdazZo1s3Jzc63s7Gxr2rRpVlxcXEH90tLSOA6BEEEQBqDcaHCjQYPSIKJ27domEHJwBB1VqlSxqlWrVrBoAOOOBi0agKSmpha5Lysry6patar13XffuawfPny4ddVVV7kEYcuXLy+4/5NPPjHrjh8/bv6eMGGC1aVLlyLbdxeEvfbaawX3v/3222bdihUrCtZNnjzZatu2bcHfGoRqAOnsscces3r06FHsdjVQ1HVbt241f2tgGR8f77Z9AAQ35oQBKBc6xPfjjz/KokWLzN8VK1aUIUOGmLlhvXr1cimrQ5Y6ROfQpEkTt9u8+OKLpVmzZtKyZUvp37+/Wa644gozbLdz507JzMw0ZZzl5OTIaaed5rKuc+fOBf9v0KCBuT169Kg0bdrUp+fovB0dGlWdOnVyWafbVRkZGbJr1y4ZPny43HzzzQVlTpw4UWT4tbj66fAlgNBFEAagXGiwpQGG80R87VCKiYmRl19+2SXw0KCrdevWHrdZo0YN2bBhg5kb9cUXX8gjjzxi5kTpPCydf6Y++eQTadSokcvjdJ/OKlWqVPB/nVflmE/mK3fbKbzOsV1H/WbNmiXdu3d32Y5ePVoW9QMQXAjCAJQ5Db7eeOMNef7556Vv374u9w0cOFDefvttue222/zatvao9enTxywTJkww6RpWrlxpesA02Nq3b59ccMEFfte9cuXKkpeXJ4GmvWIakO7evVuuvvrqoKsfgLJHEAagzH388ceSlJRkht4KD7UNHjzY9JL5E4TpdjWIOf/88yUxMVE+/fRT00PUtm1b00t2zz33yF133WXWnXvuueYqwm+//Vbi4uJk2LBhXu2jefPmsmfPHtm4caM0btzYbLdwT5q/9MrL0aNHmzbRodTs7GxZt26daauxY8d6XT/tVdMrPPXKSR2K1QVA8CNFBYAyp0GW9lS5SzWhQZgGHr/88ovP29VeL03f0Lt3bzOHbObMmaZXzZFj7LHHHpPx48ebNBV6vwY6OjypKSu8pfXTx2mKiDp16pjtB8pNN91kUlTMnTvXzB3THjtNgeFL/TSlhgawOr9O6/fMM88ErH4AylaUzs4v430AAACgEHrCAAAAbEAQBgAAYAOCMAAAABsQhAEAANiAIAwAAMAGBGEAAAA2IAgDAACwAUEYAACADQjCAAAAbEAQBgAAYAOCMAAAACl//x/X/c/V/8L9NwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.histplot(\n",
    "    data=df,\n",
    "    x=\"AF_roberta\",\n",
    "    hue=\"WAS_ART_USED_YN\",\n",
    "    bins=40,\n",
    "    alpha=0.5\n",
    ")\n",
    "plt.title(\"Provider Sentiment (RoBERTa): AI vs Non-AI\")\n",
    "plt.xlabel(\"AF sentiment\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb935578-f76e-46d4-afc7-a64d2f09422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAS_ART_USED_YN\n",
      "N                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 659\n",
      "Y                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 404\n",
      "Sorry I see the titration test now - apologies What do you mean by \"airing\" We can talk about other mask interfaces/options or alternative therapies  Maybe good to see one of our NPs to discuss next steps as well ----- Message -----      From:Deborah Bayus      Sent:4/9/2024  5:14 PM PDT        To:Patient Medical Advice Request Message List   Subject:Cpac machine I mean âairingâ?----- Message -----      From:Deborah Bayus      Sent:4/9/2024  5:14 PM PDT        To:Patient Medical Advice Request Message List   Subject:Cpac machine I did spend the night there already.  Would this be  for the same thing? What are your thoughts on âairâ?? ----- Message -----      From:Atul  Malhotra      Sent:4/8/2024  3:44 PM PDT        To:Deborah Bayus   Subject:Cpac machine It is usually a matter of finding the right mask Sometimes we can do an inlab titration study where you spend the night overnight to try to optimize the interface ----- Message -----      From:Deborah Bayus      Sent:4/7/2024  4:51 PM PDT        To:Atul  Malhotra   Subject:Cpac machine I am having difficulty with the prescribed cpac machine I am using.  It will not stay on.  When air escapes it makes a lot of noise and frightens me. Please review one I have been researching- itâs called âAiringâ?  Deborah Bayus       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"WAS_ART_USED_YN\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712a79c4-64c5-412d-828a-a83df4550205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WAS_ART_USED_YN\n",
       "N    0.256113\n",
       "Y    0.306694\n",
       "Name: AF_roberta, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.groupby(\"WAS_ART_USED_YN\")[\"AF_roberta\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc617521-07cb-49b1-8738-8e92746ec6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
